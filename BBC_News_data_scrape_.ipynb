{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0b2889cc-d053-4191-9cac-8196032953ad",
   "metadata": {},
   "source": [
    "!pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e699534-69fd-4569-bda0-c2ec0f75318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f230147-19a2-4cff-b0db-ab3061bae9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to CSV file and saving to an existing folder\n",
    "folder_path = r\"C:\\Users\\vladi\\OneDrive\\Робочий стіл\\DATA SCRAPING PRACTICE\" # choose own folder path to save the CSV file\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "csv_file = os.path.join(folder_path, \"bbc_top10_headlines.csv\") # choose your own name for the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f8a8fcd-32f2-4c1c-90a8-343200c522e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the file already exists - load existing CSV if it exists, else create empty DataFrame; track already seen titles to avoid duplicates\n",
    "if os.path.exists(csv_file):\n",
    "    existing_df = pd.read_csv(csv_file)\n",
    "    seen_titles = set(existing_df[\"title\"].tolist())\n",
    "else:\n",
    "    existing_df = pd.DataFrame(columns=[\"date\", \"title\", \"link\"])\n",
    "    seen_titles = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3bf408-21a6-4d4a-b610-00cb7223460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linking web and avoiding 403 error User-Agent\n",
    "url = \"https://www.bbc.com/\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"} # use your own User-Agent if necessary\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92bb22c-d12a-43fd-9e0a-a00020739831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape top 10 unique BBC headlines with links, skipping duplicates already in CSV. We also create named columns for the information that we extract and want to see in our final dataframe\n",
    "headlines = soup.find_all(\"h2\", {\"data-testid\": \"card-headline\"}) # use data-testid=\"card-headline\" since it's a stable, unique marker for BBC headlines (more reliable than dynamic class names that can change every day)\n",
    "\n",
    "seen_titles = set(existing_df[\"title\"].tolist())\n",
    "\n",
    "articles = []\n",
    "\n",
    "for h in headlines:\n",
    "    title = h.get_text(strip=True)\n",
    "    a_tag = h.find_parent(\"a\")\n",
    "    if a_tag and title and title not in seen_titles:\n",
    "        link = a_tag['href']\n",
    "        if not link.startswith(\"http\"):\n",
    "            link = \"https://www.bbc.com\" + link\n",
    "        articles.append({\"title\": title, \"link\": link, \"date\": \"\"})\n",
    "        seen_titles.add(title)\n",
    "    \n",
    "    if len(articles) >= 10:  \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b448880d-2872-4fc9-a6eb-0fbfaa7a37d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the code is ready for when there are less than 10 headlines (this line of code is mainly for future purposes of the project)\n",
    "while len(articles) < 10:\n",
    "    articles.append({\"title\": \"No headline available\", \"link\": \"\", \"date\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1bb6ee-49ed-4f9d-a44f-d1ec7f6e21ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting top 10 articles \n",
    "top_10_articles = articles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230d2b1f-f30d-42e4-a812-b4ec1686fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding date and time\n",
    "today = datetime.today().strftime(\"%d-%m-%Y\") # choose own date format\n",
    "for a in top_10_articles:\n",
    "    a[\"date\"] = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd36b5bc-fd09-45bd-98c6-ca6cb3a2c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to a data frame for later export\n",
    "new_df = pd.DataFrame(articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f59a28-a6fa-4c30-b19f-7ce507186d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new headlines DataFrame to CSV (overwrite existing file)\n",
    "new_df.to_csv(csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00eccc75-7331-415a-9805-4ffeb0324848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 BBC Headlines Today:\n",
      "1. I filmed what it takes to make a family meal in Gaza -> https://www.bbc.co.uk/news/resources/idt-d3d76a1d-f320-4047-8a57-cc6f567f08c0 -> Todays's date is: 06-09-2025\n",
      "2. Raid on Hyundai plant in US swept up workers on visitor visas -> https://www.bbc.com/news/articles/cy50yge052xo -> Todays's date is: 06-09-2025\n",
      "3. Analysis: What's behind Putin's uncompromising stance? -> https://www.bbc.com/news/articles/c0m40pv44kgo -> Todays's date is: 06-09-2025\n",
      "4. 'We are the troops': Inside Chicago's split communities as Trump vows to deploy National Guard -> https://www.bbc.com/news/articles/c4gj489q6e0o -> Todays's date is: 06-09-2025\n",
      "5. Trump says Venezuelan jets will be shot down if they endanger US ships -> https://www.bbc.com/news/articles/cr70511v774o -> Todays's date is: 06-09-2025\n",
      "6. Revenge & redemption - Sabalenka v Anisimova in final -> https://www.bbc.com/sport/tennis/articles/cr705zdjm28o -> Todays's date is: 06-09-2025\n",
      "7. The sunscreen scandal shocking Australia - the world's skin cancer hotspot -> https://www.bbc.com/news/articles/c4gzl41rpdqo -> Todays's date is: 06-09-2025\n",
      "8. The triumphant return of the US's Gulf Coast train -> https://www.bbc.com/travel/article/20250904-the-triumphant-return-of-the-uss-gulf-coast-train -> Todays's date is: 06-09-2025\n",
      "9. David Bowie’s secret final project discovered locked in his study -> https://www.bbc.com/news/articles/c3dpdpvj083o -> Todays's date is: 06-09-2025\n",
      "10. New Bollywood romcom sparks debate over stereotyping south India -> https://www.bbc.com/news/articles/c4gveer8wgro -> Todays's date is: 06-09-2025\n",
      "Total headlines in CSV: 10\n"
     ]
    }
   ],
   "source": [
    "# check if the project's conditions are met\n",
    "print(f\"Top {len(new_df)} BBC Headlines Today:\")\n",
    "for i, row in new_df.iterrows():\n",
    "    print(f\"{i+1}. {row['title']} -> {row['link']} -> Todays's date is: {row['date']}\")\n",
    "\n",
    "print(f\"Total headlines in CSV: {len(new_df)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
