{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071da440-5432-47cf-a154-c928e0cad041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 BBC Headlines Today:\n",
      "1. I filmed what it takes to make a family meal in Gaza -> https://www.bbc.co.uk/news/resources/idt-d3d76a1d-f320-4047-8a57-cc6f567f08c0 -> Todays's date is: 06-09-2025\n",
      "2. Raid on Hyundai plant in US swept up workers on visitor visas -> https://www.bbc.com/news/articles/cy50yge052xo -> Todays's date is: 06-09-2025\n",
      "3. Trump says Venezuelan jets will be shot down if they endanger US ships -> https://www.bbc.com/news/articles/cr70511v774o -> Todays's date is: 06-09-2025\n",
      "4. Analysis: What's behind Putin's uncompromising stance? -> https://www.bbc.com/news/articles/c0m40pv44kgo -> Todays's date is: 06-09-2025\n",
      "5. 'We are the troops': Inside Chicago's split communities as Trump vows to deploy National Guard -> https://www.bbc.com/news/articles/c4gj489q6e0o -> Todays's date is: 06-09-2025\n",
      "6. Revenge & redemption - Sabalenka v Anisimova in final -> https://www.bbc.com/sport/tennis/articles/cr705zdjm28o -> Todays's date is: 06-09-2025\n",
      "7. The sunscreen scandal shocking Australia - the world's skin cancer hotspot -> https://www.bbc.com/news/articles/c4gzl41rpdqo -> Todays's date is: 06-09-2025\n",
      "8. The triumphant return of the US's Gulf Coast train -> https://www.bbc.com/travel/article/20250904-the-triumphant-return-of-the-uss-gulf-coast-train -> Todays's date is: 06-09-2025\n",
      "9. David Bowie’s secret final project discovered locked in his study -> https://www.bbc.com/news/articles/c3dpdpvj083o -> Todays's date is: 06-09-2025\n",
      "10. New Bollywood romcom sparks debate over stereotyping south India -> https://www.bbc.com/news/articles/c4gveer8wgro -> Todays's date is: 06-09-2025\n",
      "Scraped 10 headlines today and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import os\n",
    "\n",
    "def scrape_bbc(): # entire scraping + saving logic here\n",
    "\n",
    "    # Folder and CSV file\n",
    "    folder_path = r\"C:\\Users\\vladi\\OneDrive\\Робочий стіл\\DATA SCRAPING PRACTICE\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    csv_file = os.path.join(folder_path, \"bbc_top10_headlines.csv\")\n",
    "\n",
    "    # Get webpage\n",
    "    url = \"https://www.bbc.com/\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find headline elements\n",
    "    headlines = soup.find_all(\"h2\", {\"data-testid\": \"card-headline\"})\n",
    "\n",
    "    # Collect up to 10 unique headlines\n",
    "    articles = []\n",
    "    seen_titles = set()\n",
    "    for h in headlines:\n",
    "        title = h.get_text(strip=True)\n",
    "        a_tag = h.find_parent(\"a\")\n",
    "        if a_tag and title and title not in seen_titles:\n",
    "            link = a_tag['href']\n",
    "            if not link.startswith(\"http\"):\n",
    "                link = \"https://www.bbc.com\" + link\n",
    "            articles.append({\"title\": title, \"link\": link, \"date\": \"\"})\n",
    "            seen_titles.add(title)\n",
    "        if len(articles) >= 10:\n",
    "            break\n",
    "\n",
    "    # Fill if fewer than 10 (for later projects)\n",
    "    while len(articles) < 10:\n",
    "        articles.append({\"title\": \"No headline available\", \"link\": \"\", \"date\": \"\"})\n",
    "\n",
    "    # Add today's date\n",
    "    today = datetime.today().strftime(\"%d-%m-%Y\")\n",
    "    for a in articles:\n",
    "        a[\"date\"] = today\n",
    "\n",
    "    # Convert to DataFrame and save CSV\n",
    "    new_df = pd.DataFrame(articles)\n",
    "    new_df.to_csv(csv_file, index=False)\n",
    "\n",
    "    # Print confirmation\n",
    "    print(f\"Top {len(new_df)} BBC Headlines Today:\")\n",
    "    for i, row in new_df.iterrows():\n",
    "        print(f\"{i+1}. {row['title']} -> {row['link']} -> Todays's date is: {row['date']}\")\n",
    "\n",
    "    print(f\"Scraped {len(new_df)} headlines today and saved to CSV.\")\n",
    "\n",
    "# run every day at 8:00 AM\n",
    "#schedule.every().day.at(\"08:00\").do(scrape_bbc)\n",
    "# test run - should print out the desired result\n",
    "schedule.every(1).minutes.do(scrape_bbc)\n",
    "\n",
    "# repeated automation with a running Jupyter notebook (can be run as a standalone Python script in CMD/Terminal or as a background task with some minor manipulations)\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    # time.sleep(60) # original automated setting\n",
    "    time.sleep(10) # testing time setting \n",
    "    # make sure sleep time is constantly present in the code to avoid CPU overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca1974-3bae-4730-98fa-e4ca53eb46ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
